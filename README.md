# Lasso回归求解算法的性能对比实验报告
## 一、实验目的
本实验针对Lasso回归问题，系统对比**梯度下降（GD）**、**随机梯度下降（SGD）**、**近端梯度下降（PGD）**、**快速近端梯度下降（FISTA）**、**自适应近端梯度下降（APGD）**、**坐标下降（CD）**、**交替方向乘子法（ADMM）**共7类求解算法的收敛速度、损失稳定性与拟合精度。同时分析**数据稀疏度**和**样本-特征维度组合（n,p）** 对算法性能的影响，为不同数据场景下Lasso回归的算法选型提供量化依据。

- **目标函数**：
$$\min_{\beta} \frac{1}{2n} \|y - X\beta\|_2^2 + \lambda\|\beta\|_1$$
- **正则化参数**：
$$\lambda = 0.1$$

## 二、实验设置
### 2.1 数据生成
实验采用模拟数据构建Lasso回归任务，数据生成公式为：
$$y = Xw_{\text{true}} + \epsilon$$
其中各组件的生成规则如下：
- **特征矩阵** `X`：维度为 `(n,p)`，元素独立服从标准正态分布 `N(0,1)`；
- **真实参数** `w_true`：设置两种稀疏度水平，非零元素服从标准正态分布：
  - 低稀疏：`sparsity=0.01`（仅1%的参数非零）；
  - 中稀疏：`sparsity=0.1`（10%的参数非零）；
- **噪声项** `ε`：服从 `N(0,0.1^2)`，模拟真实数据的观测误差。

### 2.2 对比算法与参数配置
各类算法的核心参数配置如表1所示：

表1 算法参数配置表
| 算法名称       | 核心参数配置                                                                 |
|----------------|------------------------------------------------------------------------------|
| 梯度下降（GD） | 学习率 `lr=0.01`，最大迭代次数 `max_iter=5000`                               |
| 随机梯度下降（SGD） | 初始学习率 `init_lr=0.01`，学习率衰减系数 `0.995`，批量大小随样本量自适应（`n<100`时取16，`n≥100`时取32） |
| 近端梯度下降（PGD） | 学习率 `lr=0.01`，采用软阈值算子实现近端映射                                 |
| 快速近端梯度下降（FISTA） | 学习率 `lr=0.01`，引入动量项加速收敛                                         |
| 自适应近端梯度下降（APGD） | 自适应线搜索确定学习率，最大迭代次数 `max_iter=5000`                         |
| 坐标下降（CD） | 按坐标循环更新，闭式解求解单变量优化问题                                     |
| 交替方向乘子法（ADMM） | 惩罚参数 `ρ ∈ {0.5,1.0,5.0}`，最大迭代次数 `max_iter=5000`                   |

### 2.3 评估指标
- **收敛速度**：损失值下降到稳定值所需的迭代次数；
- **损失稳定性**：收敛后损失值的波动幅度；
- **最终损失值**：迭代终止时的损失函数值，反映模型拟合精度。

### 2.4 实验场景
选取2个典型的维度组合，分别测试两种稀疏度下的算法性能：
1. **场景1**：`n=500, p=100`（样本量大于特征数，低维场景）；
2. **场景2**：`n=100, p=500`（样本量小于特征数，高维场景）。

## 三、实验结果与分析
实验共生成6张收敛曲线图（**前3张为 `sparsity=0.01`，后3张为 `sparsity=0.1`**），以下结合图表展开详细分析。

### 3.1 低稀疏场景（sparsity=0.01）
#### 3.1.1 场景1：n=500, p=100

<div align="center">
  <img src="convergence_n500_p100_0.01.png" alt="低稀疏-n500-p100收敛曲线" width="60%">
</div>

**核心分析**：
1. **收敛速度排名**：FISTA > ADMM(`ρ=1.0/5.0`) > PGD > APGD > SGD > GD；
2. **关键现象**：
   - FISTA的收敛速度显著快于PGD，验证了动量项对近端梯度下降的加速效果；
   - ADMM的参数敏感性明显：`ρ=0.5` 收敛最慢（跑满5000次迭代），`ρ=1.0` 和 `ρ=5.0` 收敛速度接近，100次迭代内损失稳定；
   - SGD和GD收敛最慢，且SGD因随机梯度方差存在明显的损失波动；
   - GD误差反而增大，两个原因：第一，GD 前期依赖梯度下降快速靠近最优解，但L1 正则的非光滑性导致梯度在最优解附近出现 "突变"；第二，固定学习率（代码中`lr=0.01`）在后期过大，参数更新时 "越过" 最优解，导致损失值反向增大；
   - CD算法很快即可将损失值从初始的10左右降至`6×10^{-2}`（0.06）以下，但收敛后震荡明显。

## CD算法收敛迭代次数统计
| 数据场景（n,p） | 收敛迭代次数 | 损失值变化阈值 |
|----------------|--------------|----------------|
| (100, 50)      | 107次        | < 0.0001       |
| (100, 100)     | 1次          | < 0.0001       |
| (100, 500)     | 41次         | < 0.0001       |
| (500, 50)      | 117次        | < 0.0001       |
| (500, 100)     | 1次          | < 0.0001       |
| (500, 500)     | 85次         | < 0.0001       |
| (1000, 50)     | 1次          | < 0.0001       |
| (1000, 500)    | 144次        | < 0.0001       |

### 结果分析
从统计结果可以看出：
1. 当特征数 `p ≤ 100` 时（如`(100,100)`、`(500,100)`、`(1000,50)`），CD算法仅需**1次迭代**即可收敛，说明低维场景下CD的效率极高；
2. 当特征数 `p = 500` 时（如`(100,500)`、`(500,500)`、`(1000,500)`），收敛迭代次数随样本量 `n` 增大而线性增加，反映CD在高维场景下计算复杂度有优势。

#### 3.1.2 场景2：n=100, p=500
<div align="center">
  <img src="convergence_n100_p500_0.01_iteration=500.png" alt="低稀疏-n100-p500收敛曲线" width="60%">
</div>

**核心分析**：
1. **收敛速度排名**：CD > FISTA > ADMM(`ρ=1.0`) > APGD > PGD > SGD > GD；
2. **关键现象**：
   - 高维场景下CD算法的优势进一步凸显，**80次迭代**内损失值从3左右降至`1×10^0`以下，远快于其他算法；
   - SGD的损失波动幅度增大，最终损失值高于其他算法，原因是高维场景下随机梯度的方差较大；
   - ADMM的最优参数变为 `ρ=1.0`，`ρ=5.0` 因惩罚过重导致收敛速度下降。

#### 3.1.3 低稀疏场景总结
低稀疏（`sparsity=0.01`）下，CD算法在低维和高维场景中均表现出绝对的收敛速度优势，ADMM需选择`ρ=1.0`才能获得较好性能。

### 3.2 中稀疏场景（sparsity=0.1）
#### 3.2.1 场景1：n=500, p=100
<div align="center">
  <img src="convergence_n500_p100_0.1.png" alt="中稀疏-n500-p100收敛曲线" width="60%">
</div>

**核心分析**：
1. **收敛速度排名**：ADMM(`ρ=1.0/5.0`) > APGD > FISTA > CD > PGD > SGD > GD；
2. **关键现象**：
   - 稀疏度提升后，FISTA超越CD的收敛速度，40次迭代内损失值降至`6×10^{-1}`（0.6）以下；
   - ADMM算法表现优异，`ρ=1.0`和`ρ=5.0`均表现良好，收敛速度最快。

#### 3.2.2 场景2：n=100, p=500
<div align="center">
  <img src="convergence_n100_p500_0.1_iteration=1000.png" alt="中稀疏-n100-p500收敛曲线" width="60%">
</div>

**核心分析**：
1. **收敛速度排名**：CD > ADMM(`ρ=1.0/0.5`) > ADMM(`ρ=5.0`) > FISTA > APGD > PGD > SGD > GD；
2. **关键现象**：
   - 高维+中稀疏场景下，CD算法再次展现出优势，100次迭代内损失值稳定在`5×10^0`（5）左右；
   - SGD最终损失值比低稀疏场景高15%，不适合高维中稀疏数据。

#### 3.2.3 中稀疏场景总结
中稀疏（`sparsity=0.1`）下，低维场景中ADMM表现最优，高维场景中CD仍为首选，ADMM的`ρ=1.0`依旧是最优参数配置。

### 3.3 稀疏度与维度的交叉影响分析
**核心结论**：
1. **稀疏度的影响**：低稀疏下CD算法优势显著，中稀疏下ADMM的加速效果更突出；
2. **维度的影响**：高维场景下（`p>n`），所有算法的收敛速度均有所下降，但CD的鲁棒性最强；
3. **算法适应性**：
   - CD算法：对稀疏度和维度的适应性最强，尤其适合高维低稀疏数据；
   - ADMM算法：在`ρ=1.0`时表现最佳，对稀疏度和维度的变化较敏感。

## 四、关键结论
### 4.1 算法性能综合排名
综合两种稀疏度和两种维度场景，算法的收敛速度与稳定性综合排名为：
`CD > ADMM(ρ=1.0) > FISTA > APGD > PGD > SGD > GD`

### 4.2 场景化算法选型建议
| 数据场景                | 推荐算法       | 推荐理由                                   |
|-------------------------|----------------|--------------------------------------------|
| 低维低稀疏（`n>p`, `sparsity=0.01`） | CD             | 收敛最快，损失稳定性最高                   |
| 低维中稀疏（`n>p`, `sparsity=0.1`）  | ADMM（`ρ=1.0`） | 兼顾收敛速度与拟合精度                     |
| 高维数据（`n<p`）| CD             | 对高维冗余特征的适应性最强                 |
| 大规模数据              | SGD（调优后）| 计算成本低，可通过增大批量降低梯度方差     |
| 高精度要求场景          | ADMM（`ρ=1.0`） | 收敛后损失值稳定，拟合精度高               |

### 4.3 参数配置建议
1. **ADMM**：惩罚参数`ρ`建议设置为1.0，避免使用0.5等过小值；
2. **SGD**：高维场景下建议增大批量大小（如64），降低梯度方差；
3. **FISTA**：学习率可设置为0.01，无需额外调优即可获得较好性能。

### 4.4 稀疏度的影响规律
- 稀疏度越低，CD算法的优势越明显，原因是低稀疏下坐标更新的针对性更强；
- 稀疏度越高，ADMM（`ρ=1.0`）算法的表现越好。

## 五、实验总结
本实验通过对比7类Lasso回归求解算法在不同稀疏度和维度场景下的性能，明确了各类算法的适用范围和最优参数配置。实验结果表明：
1. **CD和ADMM**是综合性能最优的两种算法，分别适用于高维低稀疏和低维中稀疏场景；
2. **ADMM**的性能高度依赖惩罚参数的选择，`ρ=1.0`是通用最优配置；
3. **GD和SGD**仅适用于小规模低维数据，在高维场景中表现较差。
